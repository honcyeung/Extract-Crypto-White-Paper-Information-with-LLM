{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6108d2",
   "metadata": {},
   "source": [
    "# 1. Read Crypto White Paper PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db197dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pdf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    except Exception as e:\n",
    "        # print(f\"Error reading PDF with pdfplumber: {e}\")\n",
    "        # return None\n",
    "        raise RuntimeError(f\"Failed to read PDF file: {e}\")\n",
    "    return text\n",
    "\n",
    "# path = \"whitepapers\"\n",
    "# pdf_file = \"whitepaper_abjcoin.pdf\"  \n",
    "# file_path = os.path.join(path, pdf_file)\n",
    "extracted_text = extract_text_from_pdf(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if extracted_text:\n",
    "    document = Document(page_content = extracted_text, metadata = {\"source\": pdf_file})\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200, length_function = len, separators = [\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "    chunks = text_splitter.split_documents([document])\n",
    "\n",
    "    for i, chunk in enumerate(chunks[:5]):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\")\n",
    "        print(f\"{chunk.page_content[:100]}...\")\n",
    "        print(f\"Metadata: {chunk.metadata}\\n\")\n",
    "        print(chunk.page_content, \"\\n\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    raise ValueError(\"No text extracted from the PDF file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c5ce6",
   "metadata": {},
   "source": [
    "# 2. Set Up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2177d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "AZURE_ENDPOINT = os.getenv(\"AZURE_ENDPOINT\")\n",
    "API_VERSION = os.getenv(\"API_VERSION\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "if not AZURE_ENDPOINT or not API_KEY:\n",
    "    raise ValueError(\"AZURE_ENDPOINT and API_KEY environment variables must be set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1583adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment = MODEL,\n",
    "    openai_api_version = API_VERSION,\n",
    "    azure_endpoint = AZURE_ENDPOINT,\n",
    "    openai_api_key = API_KEY,\n",
    "    temperature = 0 # For consistent structured output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee8b1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Pydantic Schemas\n",
    "\n",
    "class CryptoProjectInfo(BaseModel):\n",
    "    project_name: Optional[str] = Field(default = None, description = \"Full name of the cryptocurrency project.\")\n",
    "    ticker_symbol: Optional[str] = Field(default = None, description = \"Abbreviated ticker symbol (e.g., BTC, ETH, ABJC).\")\n",
    "    consensus_mechanism: Optional[str] = Field(default = None, description = \"Consensus mechanism used (e.g., 'Proof of Work', 'Proof of Stake').\")\n",
    "    key_features: List[str] = Field(default_factory = list, description = \"Unique features or innovations of the project.\")\n",
    "\n",
    "class Tokenomics(BaseModel):\n",
    "    token_description: str = Field(default = None, description = \"Description of the token\")\n",
    "    total_supply: Optional[str] = Field(default = None, description = \"How tokens are distributed.\")\n",
    "    utility: Optional[str] = Field(default = None, description = \"Primary use cases or utility of the token.\")\n",
    "\n",
    "class TeamMember(BaseModel):\n",
    "    name: str = Field(default = None, description = \"Names of the team member.\")\n",
    "    role: Optional[str] = Field(default = None, description = \"Role or title of the team member.\")\n",
    "    responsibilities: Optional[str] = Field(default = None, description = \"Key responsibilities or contributions of the team member.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59697378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_chunk(chunk, output_schema):\n",
    "    extraction_chain = llm.with_structured_output(output_schema)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert at extracting structured information from cryptocurrency whitepapers. Extract the following details about the project mentioned in the text. Focus only on information directly present.\"),\n",
    "        (\"human\", \"Extract information about the crypto project from the following text:\\n\\n{text}\")\n",
    "    ])\n",
    "\n",
    "    chain_with_prompt = prompt | extraction_chain\n",
    "\n",
    "    extracted_data_list = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        try:\n",
    "            # invoke the LangChain structured output chain\n",
    "            extracted_info = chain_with_prompt.invoke({\"text\": chunk.page_content})\n",
    "            # extracted_data_list.append(extracted_info.dict()) \n",
    "            extracted_data_list.append(extracted_info.model_dump()) # convert Pydantic model to dictionary\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting from chunk {i+1}: {e}\")\n",
    "            # Log the full error for debugging if needed\n",
    "\n",
    "    return extracted_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a00d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = dict()\n",
    "\n",
    "final_project_info = CryptoProjectInfo()\n",
    "extracted_data_list = extract_info_from_chunk(chunk, CryptoProjectInfo)\n",
    "\n",
    "for data in extracted_data_list:\n",
    "    current_pydantic_model = CryptoProjectInfo.model_validate(data)\n",
    "\n",
    "    # merge results\n",
    "    if current_pydantic_model.project_name and not final_project_info.project_name:\n",
    "        final_project_info.project_name = current_pydantic_model.project_name\n",
    "    if current_pydantic_model.ticker_symbol and not final_project_info.ticker_symbol:\n",
    "        final_project_info.ticker_symbol = current_pydantic_model.ticker_symbol\n",
    "    if current_pydantic_model.consensus_mechanism and not final_project_info.consensus_mechanism:\n",
    "        final_project_info.consensus_mechanism = current_pydantic_model.consensus_mechanism\n",
    "    \n",
    "    # merge results from lists\n",
    "    for feature in current_pydantic_model.key_features:\n",
    "        if feature not in final_project_info.key_features:\n",
    "            final_project_info.key_features.append(feature)\n",
    "\n",
    "final_output.update(final_project_info.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7721d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tokenomics_info = Tokenomics()\n",
    "extracted_data_list2 = extract_info_from_chunk(chunk, Tokenomics)\n",
    "\n",
    "for data in extracted_data_list2:\n",
    "    current_pydantic_model = Tokenomics.model_validate(data)\n",
    "\n",
    "    # merge results\n",
    "    if current_pydantic_model.token_description and not final_tokenomics_info.token_description:\n",
    "        final_tokenomics_info.token_description = current_pydantic_model.token_description\n",
    "    if current_pydantic_model.total_supply and not final_tokenomics_info.total_supply:\n",
    "        final_tokenomics_info.total_supply = current_pydantic_model.total_supply\n",
    "    if current_pydantic_model.utility and not final_tokenomics_info.utility:\n",
    "        final_tokenomics_info.utility = current_pydantic_model.utility\n",
    "        \n",
    "final_output.update(final_tokenomics_info.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a64e3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_team_members = TeamMember()\n",
    "extracted_data_list3 = extract_info_from_chunk(chunk, TeamMember)\n",
    "\n",
    "for data in extracted_data_list3:\n",
    "    current_pydantic_model = TeamMember.model_validate(data)\n",
    "\n",
    "    # merge results\n",
    "    if current_pydantic_model.name and not final_team_members.name:\n",
    "        final_team_members.name = current_pydantic_model.name\n",
    "    if current_pydantic_model.role and not final_team_members.role:\n",
    "        final_team_members.role = current_pydantic_model.role\n",
    "    if current_pydantic_model.responsibilities and not final_team_members.responsibilities:\n",
    "        final_team_members.responsibilities = current_pydantic_model.responsibilities\n",
    "        \n",
    "final_output.update(final_team_members.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90928197",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e928972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
